{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yp1hcla-FLMc"
      },
      "outputs": [],
      "source": [
        "# Copyright (c) 2023 William Locke\n",
        "\n",
        "# This source code is licensed under the license found in the\n",
        "# LICENSE file in the root directory of this source tree."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PczBQaI0FPKf"
      },
      "source": [
        "This notebook is intended to be run in Google Colab with access to corresponding Google Drive files. If running locally or on another service, change import and install code accordingly.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/WilliamLockeIV/segment-anything/blob/main/notebooks/Tree_Detection_and_Segmentation.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPcr6jjYXG5D"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPFN9IRpXLvz"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!unzip '/content/drive/MyDrive/Tree Project/Data/NEONTreeEvaluation/training.zip' -d \"/content/training\"\n",
        "!unzip '/content/drive/MyDrive/Tree Project/Data/NEONTreeEvaluation/annotations.zip' -d \"/content\"\n",
        "!unzip '/content/drive/MyDrive/Tree Project/Data/example_mosaic/SA7_RGB_Multi.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIXechB4y5rQ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install rasterio\n",
        "!pip install supervision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OH911DqGGOV"
      },
      "outputs": [],
      "source": [
        "#@title Copy GroundingDINO from IDEA-Research github repository\n",
        "%%capture\n",
        "\n",
        "%cd /content\n",
        "import os\n",
        "if not os.path.exists('/content/weights'):\n",
        "  !mkdir /content/weights\n",
        "!git clone https://github.com/IDEA-Research/GroundingDINO.git\n",
        "%cd /content/GroundingDINO\n",
        "!pip install -q .\n",
        "%cd /content/weights\n",
        "!wget -q https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha2/groundingdino_swinb_cogcoor.pth\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oh-6BNFGIy-"
      },
      "outputs": [],
      "source": [
        "#@title Copy SAM from personal github repository\n",
        "%%capture\n",
        "\n",
        "%cd /content\n",
        "import os\n",
        "if os.path.exists('/content/segment-anything'):\n",
        "  !rm -r /content/segment-anything\n",
        "!git clone https://github.com/WilliamLockeIV/segment-anything.git\n",
        "%cd /content/segment-anything\n",
        "!pip install -q .\n",
        "%cd /content/weights\n",
        "!wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuXDYJgZeJP3"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GHDU9ehGRRQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import torch\n",
        "import rasterio\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import supervision as sv\n",
        "import matplotlib.pyplot as plt\n",
        "import xml.etree.ElementTree as ET\n",
        "from segment_and_detect_anything.detr import box_ops\n",
        "from GroundingDINO.groundingdino.util.inference import Model\n",
        "from segment_and_detect_anything import NEONTreeDataset, sam_model_registry, SamPredictor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpuYo5XYeBb0"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufYc1gD6I47q"
      },
      "outputs": [],
      "source": [
        "# Load GroundingDINO Model\n",
        "%%capture\n",
        "GROUNDING_DINO_CONFIG_PATH = \"/content/GroundingDINO/groundingdino/config/GroundingDINO_SwinB_cfg.py\"\n",
        "GROUNDING_DINO_CHECKPOINT_PATH = \"/content/weights/groundingdino_swinb_cogcoor.pth\"\n",
        "gd_model = Model(model_config_path=GROUNDING_DINO_CONFIG_PATH, model_checkpoint_path=GROUNDING_DINO_CHECKPOINT_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNXvXhuZJBx-"
      },
      "outputs": [],
      "source": [
        "# Load SAM Model\n",
        "sam_model = sam_model_registry[\"vit_h\"](checkpoint=\"/content/weights/sam_vit_h_4b8939.pth\")\n",
        "sam_predictor = SamPredictor(sam_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCgwPjkgmVPm"
      },
      "source": [
        "# Example 1: Clearly Separated Trees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZA7oLfKmLyZ"
      },
      "outputs": [],
      "source": [
        "# Load Image\n",
        "rgb_path = \"/content/SA7_RGB_Multi_transparent_mosaic_group1_2_2.tif\"\n",
        "with rasterio.open(rgb_path) as img :\n",
        "  rgb_img = img.read()[:-1].transpose(1,2,0)\n",
        "bgr_img = rgb_img[:,:,::-1]\n",
        "\n",
        "# Show image\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.axis('off')\n",
        "plt.imshow(rgb_img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3J6OseUnaFg"
      },
      "source": [
        "## Detect with GroundingDINO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOlhY5mrnUk-"
      },
      "outputs": [],
      "source": [
        "# Detect Trees\n",
        "classes = ['tree']\n",
        "threshold = 0.2\n",
        "\n",
        "gd_boxes_raw = gd_model.predict_with_classes(\n",
        "    image=bgr_img,\n",
        "    classes=classes,\n",
        "    box_threshold=threshold,\n",
        "    text_threshold=threshold)\n",
        "\n",
        "gd_boxes = box_ops.custom_nms(gd_boxes_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13mdYXwjntgB"
      },
      "outputs": [],
      "source": [
        "box_annotator = sv.BoxAnnotator(thickness=10, color=sv.Color.red())\n",
        "gd_plot = box_annotator.annotate(scene=bgr_img.copy(), detections=gd_boxes, skip_label=True)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.axis('off')\n",
        "plt.imshow(gd_plot[:,:,::-1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UQTAJhkoJ1i"
      },
      "source": [
        "## Segment with SAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVp7tNgdoLKg"
      },
      "outputs": [],
      "source": [
        "sam_predictor.set_image(rgb_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFnEW8WwoOQD"
      },
      "outputs": [],
      "source": [
        "def segment(sam_predictor: SamPredictor, boxes: np.ndarray) -> np.ndarray:\n",
        "    result_masks = []\n",
        "    for box in boxes:\n",
        "        masks, scores, logits = sam_predictor.predict(\n",
        "            box=box,\n",
        "            multimask_output=False\n",
        "        )\n",
        "        index = np.argmax(scores)\n",
        "        result_masks.append(masks[index])\n",
        "    return np.array(result_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dI50kCZ8q2s-"
      },
      "outputs": [],
      "source": [
        "gd_boxes.mask = segment(sam_predictor, gd_boxes.xyxy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OTGWEPEohIp"
      },
      "outputs": [],
      "source": [
        "mask_annotator = sv.MaskAnnotator()\n",
        "gd_masks = mask_annotator.annotate(scene=gd_plot.copy(), detections=gd_boxes)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.axis('off')\n",
        "plt.imshow(gd_masks[:,:,::-1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp3JmdhEoW1P"
      },
      "source": [
        "# Example 2: Closely Grouped Trees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSdC8G1AKFQa"
      },
      "outputs": [],
      "source": [
        "# Load Image\n",
        "\n",
        "ds = NEONTreeDataset(image_path='/content/training', ann_path='/content/annotations')\n",
        "img = ds.get_image('2018_BART_4_322000_4882000_image_crop')\n",
        "rgb_img = img['rgb']\n",
        "bgr_img = rgb_img[:,:,::-1].copy()\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.axis('off')\n",
        "plt.imshow(rgb_img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwSP-b1lCoxr"
      },
      "source": [
        "## Detect with GroundingDINO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3mdW0OpOaoi"
      },
      "outputs": [],
      "source": [
        "# Detect Trees\n",
        "classes = ['tree']\n",
        "threshold = 0.2\n",
        "\n",
        "gd_boxes_raw = gd_model.predict_with_classes(\n",
        "    image=bgr_img,\n",
        "    classes=classes,\n",
        "    box_threshold=threshold,\n",
        "    text_threshold=threshold)\n",
        "\n",
        "gd_boxes = box_ops.custom_nms(gd_boxes_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfLya-Msetth"
      },
      "outputs": [],
      "source": [
        "box_annotator = sv.BoxAnnotator(thickness=2, color=sv.Color.red())\n",
        "gd_plot = box_annotator.annotate(scene=bgr_img.copy(), detections=gd_boxes, skip_label=True)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.axis('off')\n",
        "plt.imshow(gd_plot[:,:,::-1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErMGv9V-XfMT"
      },
      "source": [
        "## True Annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2v2DLEvXiJu"
      },
      "outputs": [],
      "source": [
        "true_boxes_raw = img['annotation']\n",
        "true_boxes = sv.Detections(xyxy=true_boxes_raw,\n",
        "                           confidence=np.ones(len(true_boxes_raw)),\n",
        "                           class_id=np.zeros(len(true_boxes_raw), dtype='int64'))\n",
        "\n",
        "box_annotator = sv.BoxAnnotator(thickness=2, color=sv.Color.red())\n",
        "true_plot = box_annotator.annotate(scene=bgr_img.copy(), detections=true_boxes, skip_label=True)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.axis('off')\n",
        "plt.imshow(true_plot[:,:,::-1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quw2QEbfr9DM"
      },
      "source": [
        "## Segment with SAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVpEc2s9aY92"
      },
      "outputs": [],
      "source": [
        "sam_predictor.set_image(rgb_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8yLwzAdwlsv"
      },
      "outputs": [],
      "source": [
        "def segment(sam_predictor: SamPredictor, boxes: np.ndarray) -> np.ndarray:\n",
        "    result_masks = []\n",
        "    for box in boxes:\n",
        "        masks, scores, logits = sam_predictor.predict(\n",
        "            box=box,\n",
        "            multimask_output=False\n",
        "        )\n",
        "        index = np.argmax(scores)\n",
        "        result_masks.append(masks[index])\n",
        "    return np.array(result_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqJHRneZ0CBj"
      },
      "outputs": [],
      "source": [
        "gd_boxes.mask = segment(sam_predictor, gd_boxes.xyxy)\n",
        "true_boxes.mask = segment(sam_predictor, true_boxes.xyxy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-OTVwk--3WA"
      },
      "outputs": [],
      "source": [
        "mask_annotator = sv.MaskAnnotator()\n",
        "\n",
        "gd_masks = mask_annotator.annotate(scene=gd_plot.copy(), detections=gd_boxes)\n",
        "true_masks = mask_annotator.annotate(scene=true_plot.copy(), detections=true_boxes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOahXmA9_UGk"
      },
      "source": [
        "## Plot Masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfVGwPwQ_S2a"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(15,10))\n",
        "\n",
        "axs[0].set_title('GroundingDINO', fontsize=22)\n",
        "axs[0].imshow(gd_masks[:,:,::-1])\n",
        "axs[1].set_title('True Detection', fontsize=22)\n",
        "axs[1].imshow(true_masks[:,:,::-1])\n",
        "plt.tight_layout()\n",
        "for ax in axs.ravel():\n",
        "  ax.axis('off')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
